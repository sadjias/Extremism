{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736aa058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.......... for data .................\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "#.......... for plotting ..............\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#.......... for text processing .......\n",
    "import nltk\n",
    "import html\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#.......... for sentiment ..............\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#.......... for vectorizer ..............\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "#.............. EDA .......................\n",
    "from collections import Counter\n",
    "\n",
    "#.............. Imbalanced dataset ........\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba9e18",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('cleaned_tweets.pkl')\n",
    "df # 581470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby(['label'])['user.screen_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total: 581470 tweets\n",
    "tweets = df_clean.groupby('label')['cleaned_text'].count().to_frame(name='count')\n",
    "tweets['percentage'] = ((tweets['count'] / tweets['count'].sum()) * 100).round(1)\n",
    "print(tweets)\n",
    "\n",
    "fig = px.bar(tweets, y = \"count\", text=\"percentage\", labels=dict(label=\"Extremist groups\", count=\"\"))\n",
    "fig.update_layout(title=\"Percentage of tweets per group\", title_x= 0.5, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# 23.8% - 39.9% - 36.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec618d",
   "metadata": {},
   "source": [
    "## Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affe8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[['id', 'user.screen_name','text','cleaned_text_punc', 'cleaned_text']]\n",
    "y = df_clean['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc407a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the random undersampler\n",
    "rus = RandomUnderSampler() \n",
    "\n",
    "# resampling X, y\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "# new class distribution\n",
    "print(Counter(y_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([X_rus.reset_index(drop=True), y_rus.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total: 418938 tweets\n",
    "tweets = df_balanced.groupby('label')['cleaned_text'].count().to_frame(name='count')\n",
    "tweets['percentage'] = ((tweets['count'] / tweets['count'].sum()) * 100).round(1)\n",
    "print(tweets)\n",
    "\n",
    "fig = px.bar(tweets, y = \"count\", text=\"percentage\", labels=dict(label=\"Extremist groups\", count=\"\"))\n",
    "fig.update_layout(title=\"Percentage of tweets per group\", title_x= 0.5, showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb267d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.groupby(['label'])['user.screen_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f798ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5195544",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = df_balanced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc671757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Add VADER metrics to dataframe\n",
    "df_sentiment['compound'] = [analyzer.polarity_scores(v)['compound'] for v in df_sentiment['cleaned_text']]\n",
    "df_sentiment['neg'] = [analyzer.polarity_scores(v)['neg'] for v in df_sentiment['cleaned_text']]\n",
    "df_sentiment['neu'] = [analyzer.polarity_scores(v)['neu'] for v in df_sentiment['cleaned_text']]\n",
    "df_sentiment['pos'] = [analyzer.polarity_scores(v)['pos'] for v in df_sentiment['cleaned_text']]\n",
    "\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment['compound_sentiment'] = ['negative' if x <= -0.05 \n",
    "                                     else 'positive' if x >= 0.05\n",
    "                                     else 'neutral' for x in df_sentiment['compound']]\n",
    "\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.groupby(['label'])['compound_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total: 612171 tweets\n",
    "\n",
    "tweets = df_sentiment.groupby('label')['compound_sentiment'].value_counts().to_frame(name='count').reset_index()\n",
    "tweets['percentage'] = ((tweets['count'] / tweets['count'].sum()) * 100).round(1)\n",
    "print(tweets)\n",
    "total = tweets['count'].sum()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ax = sns.barplot(x='label', y='count', hue='compound_sentiment', data=tweets,\n",
    "                 palette=\"Blues_d\")\n",
    "\n",
    "plt.title(\"Distribution Sentiment scores per group\")\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "    x = p.get_x() + p.get_width()\n",
    "    y = p.get_height()\n",
    "    ax.annotate(percentage, (x, y),ha='right')\n",
    "    \n",
    "ax.legend(title='Sentiment', shadow=True)\n",
    "ax.set(xlabel='Extremists', ylabel='Sentiment scores') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0606227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92418f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sentiment[['cleaned_text', 'compound']]\n",
    "y = df_sentiment['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa941ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "# Code from: https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "   \n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_feats =  Pipeline([\n",
    "                ('selector', NumberSelector(key='compound')),\n",
    "                ('standard', MinMaxScaler()),\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731080f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('senti_feats', senti_feats),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', np.mean(preds == y_test))\n",
    "print(classification_report(preds, y_test)) # 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c61d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(preds, y_test)\n",
    "categories = ['LWE', 'NE', 'RWE']\n",
    "make_confusion_matrix(matrix, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('senti_feats', senti_feats),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', np.mean(preds == y_test))\n",
    "print(classification_report(preds, y_test)) # 0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(preds, y_test)\n",
    "categories = ['LWE', 'NE', 'RWE']\n",
    "make_confusion_matrix(matrix, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed079d",
   "metadata": {},
   "source": [
    "# NLP Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced['cleaned_text']\n",
    "y = df_balanced['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify= y, random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape) # 335150 - training_features\n",
    "print(X_test.shape) # 83788 - test features\n",
    "\n",
    "\n",
    "#......................................................\n",
    "print(y_train.shape) # training target\n",
    "print(y_test.shape) # test target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b885789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "df_test = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c71f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e2662",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix: https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "   \n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c61511",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25362de7",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer\n",
    "count_vect = CountVectorizer(max_features=1000)\n",
    "\n",
    "# fit and transform train set. Using fit: learning vocabulary dictionary\n",
    "xtrain_count = count_vect.fit_transform(X_train)\n",
    "\n",
    "# transform test set\n",
    "xtest_count = count_vect.transform(X_test)\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "dummy = MultinomialNB()\n",
    "dummy.fit(xtrain_count, y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "pred_dummy = dummy.predict(xtest_count)\n",
    "accuracy_dummy = accuracy_score(pred_dummy, y_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy and print classification report\n",
    "print('accuracy %s' % accuracy_dummy) \n",
    "print(classification_report(pred_dummy, y_test)) # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16eee38",
   "metadata": {},
   "source": [
    "## Naive Bayes + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ca208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_balanced['cleaned_text'], df_balanced['label']\n",
    "metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    nb_bow = Pipeline([('vect', CountVectorizer(analyzer='word', max_features=5000, stop_words='english')),\n",
    "                       ('clf_nb', MultinomialNB()),\n",
    "                      ])\n",
    "    \n",
    "    nb_bow.fit(X_train, y_train)\n",
    "    pred_nb_bow = nb_bow.predict(X_test)\n",
    "    \n",
    "    metrics.append(accuracy_score(pred_nb_bow, y_test))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "accuracy_nb_bow = np.mean(metrics, axis=0).round(3)\n",
    "\n",
    "print('Mean accuracy: ', accuracy_nb_bow)\n",
    "print(classification_report(pred_nb_bow, y_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nb_bow = confusion_matrix(pred_nb_bow, y_test)\n",
    "matrix_nb_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ada6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "make_confusion_matrix(matrix_nb_bow, categories=categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342017b",
   "metadata": {},
   "source": [
    "## Naive Bayes + BOW - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15541e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2,2)], # choice whether unigram or bigram\n",
    "              'vect__max_features': (None, 5000, 10000, 50000),\n",
    "              'vect__max_df': (0.5, 0.75, 1.0),\n",
    "              'clf_nb__alpha': (1e-2, 1e-3),\n",
    "              'clf_nb__fit_prior': (True, False),\n",
    "             }\n",
    "\n",
    "# create instance of grid search by passing classifier\n",
    "gs_clf = GridSearchCV(nb_bow, parameters, n_jobs=-1, scoring='accuracy')\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_ # 1,2, Fit_prior=False meaning uniform prior used, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "y_pred = gs_clf.predict(X_test)\n",
    "accuracy_nb_bow_grid = accuracy_score(y_pred, y_test).round(3)\n",
    "df_class_report_nb_bow_grid = classification_report(y_pred, y_test, output_dict=True, digits=3)\n",
    "df_class_report_nb_bow_grid = pd.DataFrame(df_class_report_nb_bow_grid).transpose()\n",
    "print('accuracy %s' % accuracy_nb_bow_grid) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315197bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nb_bow = confusion_matrix(y_pred, y_test)\n",
    "matrix_nb_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "matrix_nb_bow_grid = make_confusion_matrix(matrix_nb_bow, categories=categories)\n",
    "matrix_nb_bow_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbffa28c",
   "metadata": {},
   "source": [
    "## Naive Bayes + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_balanced['cleaned_text'], df_balanced['label']\n",
    "metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    nb_tfidf = Pipeline([('vect', CountVectorizer(analyzer='word', max_features=5000, stop_words='english')),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf_nb', MultinomialNB()),\n",
    "                        ])\n",
    "    \n",
    "    nb_tfidf.fit(X_train, y_train)\n",
    "    pred_nb_tfidf = nb_tfidf.predict(X_test)\n",
    "    \n",
    "    metrics.append(accuracy_score(pred_nb_tfidf, y_test))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "accuracy_nb_tfidf = np.mean(metrics, axis=0).round(3)\n",
    "\n",
    "print('Mean accuracy: ', accuracy_nb_tfidf)\n",
    "print(classification_report(pred_nb_tfidf, y_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nb_tfidf = confusion_matrix(pred_nb_tfidf, y_test)\n",
    "matrix_nb_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "make_confusion_matrix(matrix_nb_tfidf, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3b3fd",
   "metadata": {},
   "source": [
    "## Naive Bayes + TFIDF - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a90c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2,2)], # choice whether unigram or bigram\n",
    "              'vect__max_features': (None, 5000, 10000, 50000),\n",
    "              'vect__max_df': (0.5, 0.75, 1.0),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf_nb__alpha': (1e-2, 1e-3),\n",
    "              'clf_nb__fit_prior': (True, False),\n",
    "             }\n",
    "\n",
    "# create instance of grid search by passing classifier\n",
    "gs_clf = GridSearchCV(nb_tfidf, parameters, n_jobs=-1, scoring='accuracy')\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_ # 1,2, None, 0.5, False, 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295833d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs_clf.predict(X_test)\n",
    "accuracy_nb_tfidf_grid = accuracy_score(y_pred, y_test).round(3)\n",
    "df_class_report_nb_tfidf_grid = classification_report(y_pred, y_test, output_dict=True, digits=3)\n",
    "df_class_report_nb_tfidf_grid = pd.DataFrame(df_class_report_nb_tfidf_grid).transpose()\n",
    "print('accuracy %s' % accuracy_nb_tfidf_grid) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report_nb_tfidf_grid.to_pickle(\"df_class_report_nb_tfidf_grid.pkl\")\n",
    "print(df_class_report_nb_tfidf_grid) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nb_tfidf = confusion_matrix(y_pred, y_test)\n",
    "matrix_nb_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "matrix_nb_tfidf_grid = make_confusion_matrix(matrix_nb_tfidf, categories=categories)\n",
    "matrix_nb_tfidf_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78cc01",
   "metadata": {},
   "source": [
    "## SVM + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55821c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_balanced['cleaned_text'], df_balanced['label']\n",
    "metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sgd_bow = Pipeline([('vect', CountVectorizer(analyzer='word', max_features=5000, stop_words='english')),\n",
    "                        ('clf_svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)),\n",
    "                       ])\n",
    "    \n",
    "    sgd_bow.fit(X_train, y_train)\n",
    "    pred_svm_bow = sgd_bow.predict(X_test)\n",
    "    \n",
    "    metrics.append(accuracy_score(pred_svm_bow, y_test))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "accuracy_svm_bow = np.mean(metrics, axis=0).round(3)\n",
    "\n",
    "print('Mean accuracy: ', accuracy_svm_bow)\n",
    "print(classification_report(pred_svm_bow, y_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_svm_bow = confusion_matrix(pred_svm_bow, y_test)\n",
    "matrix_svm_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7879a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "fig = make_confusion_matrix(matrix_svm_bow, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73921495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28f69c11",
   "metadata": {},
   "source": [
    "## SVM + BOW - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
    "                  'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                  'vect__max_df': (0.5, 0.75, 1.0),\n",
    "                  'clf_svm__alpha': (1e-2, 1e-3),\n",
    "                 }\n",
    "\n",
    "gs_clf_svm = GridSearchCV(sgd_bow, parameters_svm, n_jobs=-1, scoring='accuracy')\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_ # 1.2, None, 1.0, 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad27dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "y_pred = gs_clf_svm.predict(X_test)\n",
    "accuracy_svm_bow_grid = accuracy_score(y_pred, y_test).round(3)\n",
    "df_class_report_svm_bow_grid = classification_report(y_pred, y_test, output_dict=True, digits=3)\n",
    "df_class_report_svm_bow_grid = pd.DataFrame(df_class_report_svm_bow_grid).transpose()\n",
    "\n",
    "print('accuracy %s' % accuracy_svm_bow_grid) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fab745",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_svm_bow = confusion_matrix(y_pred, y_test)\n",
    "matrix_svm_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b13e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "matrix_svm_bow_grid = make_confusion_matrix(matrix_svm_bow, categories=categories)\n",
    "matrix_svm_bow_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99cf80",
   "metadata": {},
   "source": [
    "## SVM + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1909e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_balanced['cleaned_text'], df_balanced['label']\n",
    "metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sgd_tfidf = Pipeline([('vect', CountVectorizer(analyzer='word', max_features=5000, stop_words='english')),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf_svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                         ])\n",
    "    \n",
    "    sgd_tfidf.fit(X_train, y_train)\n",
    "    pred_svm_tfidf = sgd_tfidf.predict(X_test)\n",
    "    \n",
    "    metrics.append(accuracy_score(pred_svm_tfidf, y_test))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "accuracy_svm_tfidf = np.mean(metrics, axis=0).round(3)\n",
    "\n",
    "print('Mean accuracy: ', accuracy_svm_tfidf)\n",
    "print(classification_report(pred_svm_tfidf, y_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7204d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_svm_tfidf = confusion_matrix(pred_svm_tfidf, y_test)\n",
    "matrix_svm_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "make_confusion_matrix(matrix_svm_tfidf, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f404e",
   "metadata": {},
   "source": [
    "## SVM + TFIDF - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
    "                  'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                  'vect__max_df': (0.5, 0.75, 1.0),\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf_svm__alpha': (1e-2, 1e-3),\n",
    "                 }\n",
    "\n",
    "gs_clf_svm = GridSearchCV(sgd_tfidf, parameters_svm, n_jobs=-1, scoring='accuracy')\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_ # 2.2, None, 0.75, True, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb44f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "y_pred = gs_clf_svm.predict(X_test)\n",
    "accuracy_svm_tfidf_grid = accuracy_score(y_pred, y_test).round(3)\n",
    "df_class_report_svm_tfidf_grid = classification_report(y_pred, y_test, output_dict=True, digits=3)\n",
    "df_class_report_svm_tfidf_grid = pd.DataFrame(df_class_report_svm_tfidf_grid).transpose()\n",
    "\n",
    "print('accuracy %s' % accuracy_svm_tfidf_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report_svm_tfidf_grid.to_pickle(\"df_class_report_svm_tfidf_grid.pkl\")\n",
    "print(df_class_report_svm_tfidf_grid) # 76% > 77.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefa77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_svm_tfidf = confusion_matrix(y_pred, y_test)\n",
    "matrix_svm_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['LWE', 'NE', 'RWE']\n",
    "matrix_svm_tfidf_grid = make_confusion_matrix(matrix_svm_tfidf, categories=categories)\n",
    "matrix_svm_tfidf_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55401a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9452420",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NB Count Vectors:       \", accuracy_nb_bow, \"   | \", accuracy_nb_bow_grid) # 0.73 - 0.80\n",
    "print(\"NB Tfidf:               \", accuracy_nb_tfidf, \" | \", accuracy_nb_tfidf_grid) # 0.74 - 0.81\n",
    "\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"SVM Count Vectors:      \", accuracy_svm_bow, \"   | \", accuracy_svm_bow_grid) # 0.77 - 0.77\n",
    "print(\"SVM Tfidf:              \", accuracy_svm_tfidf, \" | \", accuracy_svm_tfidf_grid) # 0.76 - 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f8639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
